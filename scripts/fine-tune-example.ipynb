{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5e6d45",
   "metadata": {},
   "source": [
    "### Fine-Tune to check HELLASWAG works\n",
    "This notebook uses the HELLASWAG inspired data generated to fine-tune a LLM. Then, it also uses a portion of the dataset to measure the model improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd47e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset, DatasetDict, Value\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch, random, numpy as np\n",
    "\n",
    "from shared_models import HellaSwagEntry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5d267",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c43dc41",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/hellaswag_format/personal_chat_sessions_train_hellaswag.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63201dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22,282 examples\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl_pydantic(path: Path):\n",
    "    \"\"\"Yield HellaSwagEntry objects parsed with Pydantic.\"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield HellaSwagEntry.model_validate_json(line)\n",
    "\n",
    "records = list(load_jsonl_pydantic(Path(DATA_PATH)))\n",
    "print(f\"Loaded {len(records):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b479b7",
   "metadata": {},
   "source": [
    "#### Explode into Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8ab9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 111410/111410 [00:00<00:00, 405379.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'choice_id'],\n",
       "        num_rows: 89128\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'choice_id'],\n",
       "        num_rows: 22282\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explode_examples(ex: HellaSwagEntry):\n",
    "    endings = [ex.ending0, ex.ending1, ex.ending2, ex.ending3, ex.ending4]\n",
    "    return [\n",
    "        {\n",
    "            \"text\": f\"{ex.context.strip()} [SEP] {endings[i].strip()}\",\n",
    "            \"label\": int(ex.label == i),   # 1 if correct ending else 0\n",
    "            \"choice_id\": i,\n",
    "        }\n",
    "        for i in range(5)\n",
    "    ]\n",
    "\n",
    "flat = [row for entry in records for row in explode_examples(entry)]\n",
    "\n",
    "ds = Dataset.from_list(flat).cast_column(\"label\",Value( \"int8\"))\n",
    "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
    "dataset = DatasetDict(train=ds[\"train\"], test=ds[\"test\"])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c145d5e",
   "metadata": {},
   "source": [
    "#### Pick a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e750430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 89128/89128 [00:45<00:00, 1963.18 examples/s]\n",
      "Map: 100%|██████████| 22282/22282 [00:10<00:00, 2144.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"  # pick any seq-cls model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "if tokenizer.pad_token is None:                # safety\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"],\n",
    "                     truncation=True,\n",
    "                     max_length=128)\n",
    "\n",
    "tokenized = dataset.map(preprocess, batched=True,\n",
    "                        remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bb445",
   "metadata": {},
   "source": [
    "#### Setting the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94adb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf746c",
   "metadata": {},
   "source": [
    "#### Building the LoRA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e663f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=2  # binary (correct vs wrong)\n",
    ")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "peft_cfg = LoraConfig(\n",
    "    r=4, lora_alpha=32, target_modules=[\"q_lin\", \"v_lin\"],\n",
    "    lora_dropout=0.01, bias=\"none\", task_type=\"SEQ_CLS\",\n",
    ")\n",
    "model = get_peft_model(base_model, peft_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ec66f",
   "metadata": {},
   "source": [
    "#### Fine tune setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a6efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\AppData\\Local\\Temp\\ipykernel_18596\\3906029495.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = Path(\"../data/models/checkpoints\")\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ckpt_dir),\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bdf83",
   "metadata": {},
   "source": [
    "#### Measure Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898be048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\AppData\\Local\\Temp\\ipykernel_19256\\3565134043.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='697' max='697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [697/697 1:18:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6691051072614667\n"
     ]
    }
   ],
   "source": [
    "baseline_metrics = trainer.evaluate()\n",
    "print(\"Baseline accuracy:\", baseline_metrics[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d6248",
   "metadata": {},
   "source": [
    "#### Let's Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30ff928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16713' max='16713' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16713/16713 5:34:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.379900</td>\n",
       "      <td>0.372303</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.856117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.368939</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.856386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.371873</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.856925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.model = model             # swap in PEFT model\n",
    "train_metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a5ac6",
   "metadata": {},
   "source": [
    "#### Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a43f6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='697' max='697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [697/697 12:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.856924872094067\n"
     ]
    }
   ],
   "source": [
    "final_metrics = trainer.evaluate()\n",
    "print(\"Final accuracy:\", final_metrics[\"eval_accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_FT_Kernel",
   "language": "python",
   "name": "llm_ft_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
