{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d47b37",
   "metadata": {},
   "source": [
    "### Reward Model with TRL RewardTrainer\n",
    "This notebook uses the TRL `RewardTrainer` (v0.17.0) to train a reward model on HellaSwag-style chat data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139e5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import Dataset\n",
    "from shared_models import HellaSwagEntry\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from trl import RewardTrainer, RewardConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7dbaa",
   "metadata": {},
   "source": [
    "#### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b085a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/hellaswag_format/personal_chat_sessions_train_hellaswag.jsonl\")\n",
    "\n",
    "def load_jsonl_pydantic(path):\n",
    "    \"\"\"Yield HellaSwagEntry objects parsed with Pydantic.\"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield HellaSwagEntry.model_validate_json(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43653cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pairwise examples\n",
    "pairs = []\n",
    "for ex in load_jsonl_pydantic(DATA_PATH):\n",
    "    endings = [ex.ending0, ex.ending1, ex.ending2, ex.ending3, ex.ending4]\n",
    "    pos_id = ex.label\n",
    "    neg_id = random.choice([i for i in range(5) if i != pos_id])\n",
    "\n",
    "    pos_txt, neg_txt = endings[pos_id].strip(), endings[neg_id].strip()\n",
    "    context = ex.context.strip()\n",
    "\n",
    "    # randomly order A/B\n",
    "    if random.random() < 0.5:\n",
    "        first, second, lbl = pos_txt, neg_txt, 1\n",
    "    else:\n",
    "        first, second, lbl = neg_txt, pos_txt, 0\n",
    "\n",
    "    pairs.append({\n",
    "        \"context\": context,\n",
    "        \"first_resp\": first,\n",
    "        \"second_resp\": second,\n",
    "        \"label\": lbl\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501a2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HF Dataset and split\n",
    "dataset = Dataset.from_list(pairs)\n",
    "train_test = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362eaffe",
   "metadata": {},
   "source": [
    "#### Prepare for RewardTrainer\n",
    "Convert to the `\"chosen\"` / `\"rejected\"` format required by RewardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f3f813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb61a2a4dfb4765a4303c848eb3c36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571fc83fb6c748e58a5318b873d913f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_to_reward(examples):\n",
    "    chosen, rejected = [], []\n",
    "    for lbl, a, b in zip(examples[\"label\"], examples[\"first_resp\"], examples[\"second_resp\"]):\n",
    "        if lbl == 1:\n",
    "            chosen.append(a)\n",
    "            rejected.append(b)\n",
    "        else:\n",
    "            chosen.append(b)\n",
    "            rejected.append(a)\n",
    "    return {\"chosen\": chosen, \"rejected\": rejected}\n",
    "\n",
    "rm_dataset = train_test.map(\n",
    "    map_to_reward,\n",
    "    batched=True,\n",
    "    remove_columns=train_test[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caadde19",
   "metadata": {},
   "source": [
    "#### Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4a80d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b581d39e8054980bd318e031eaf3c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aadhu\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d32b11a92a4e39828a123abbf5fc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dbf04c7f1b4eff9fc4c02c4c73bb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4150e0779ca54e00bd4dbd5e9efbb574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ckpt = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ef797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfb9fd6534647ec9dad9e6df0d9c575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Single‐scalar head for reward\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10beaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cfc2f",
   "metadata": {},
   "source": [
    "#### LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0180b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c51eb",
   "metadata": {},
   "source": [
    " #### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec35f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = RewardConfig(\n",
    "    output_dir=\"../data/models/reward_model_ckpts\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    max_length=128,\n",
    "    disable_dropout=False,  # keep dropout active during training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40309fdc",
   "metadata": {},
   "source": [
    "#### Initialize & Run RewardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79b3d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35215cfb01644c10827307b7893561d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04327eeacdb54587a526db029be59f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada98eac653d442e998ba1889c36c0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e103458f75de4393a90cfb58e19f8cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810bf806320e4d1093dd13029e78b02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a505d20874dd488d889732999857118c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rm_dataset[\"train\"],\n",
    "    eval_dataset=rm_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=peft_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71806343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                    </span>┃<span style=\"font-weight: bold\"> rejected_text                                              </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [0.4584, 0.5416] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [0.4272, 0.5728] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [0.4752, 0.5248] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [0.4545, 0.5455] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [0.4584, 0.5416] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [0.4272, 0.5728] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [0.4752, 0.5248] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [0.4545, 0.5455] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 15:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: {'eval_loss': 0.7329193949699402, 'eval_model_preparation_time': 0.0039, 'eval_accuracy': 0.2591093117408907, 'eval_runtime': 45.0688, 'eval_samples_per_second': 49.391, 'eval_steps_per_second': 1.553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\utils.py:790: UserWarning: There are 3 out of 2226 instances where the predictions for both options are equal. These instances are ignored in the accuracy computation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline:\", trainer.evaluate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c0cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3753' max='3753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3753/3753 46:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.994602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.012975</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.995502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.995951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                    </span>┃<span style=\"font-weight: bold\"> rejected_text                                              </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [0.9982, 0.0018] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [0.9998, 0.0002] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [0.9999, 0.0001] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [0.9999, 0.0001] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [0.9982, 0.0018] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [0.9998, 0.0002] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [0.9999, 0.0001] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [0.9999, 0.0001] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\utils.py:790: UserWarning: There are 3 out of 2226 instances where the predictions for both options are equal. These instances are ignored in the accuracy computation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                    </span>┃<span style=\"font-weight: bold\"> rejected_text                                              </span>┃<span style=\"font-weight: bold\"> logits     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\utils.py:790: UserWarning: There are 3 out of 2226 instances where the predictions for both options are equal. These instances are ignored in the accuracy computation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                    </span>┃<span style=\"font-weight: bold\"> rejected_text                                              </span>┃<span style=\"font-weight: bold\"> logits     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\utils.py:790: UserWarning: There are 3 out of 2226 instances where the predictions for both options are equal. These instances are ignored in the accuracy computation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3753, training_loss=0.052317084613050936, metrics={'train_runtime': 2782.2375, 'train_samples_per_second': 21.576, 'train_steps_per_second': 1.349, 'total_flos': 0.0, 'train_loss': 0.052317084613050936, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8da37289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                    </span>┃<span style=\"font-weight: bold\"> rejected_text                                              </span>┃<span style=\"font-weight: bold\"> logits     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ [CLS] 60k [SEP]                │ [CLS] quite the total there! [SEP]                         │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] saaptiya [SEP]           │ [CLS] i completely get that, it ' s frustrating. [SEP]     │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] sure [SEP]               │ [CLS] sounds good! [SEP]                                   │ [1.0, 0.0] │\n",
       "├────────────────────────────────┼────────────────────────────────────────────────────────────┼────────────┤\n",
       "│ [CLS] thanks [SEP]             │ [CLS] awesome, that ' s a healthy amount! [SEP]            │ [1.0, 0.0] │\n",
       "└────────────────────────────────┴────────────────────────────────────────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: {'eval_loss': 0.012009366415441036, 'eval_model_preparation_time': 0.0039, 'eval_accuracy': 0.9959514170040485, 'eval_runtime': 56.725, 'eval_samples_per_second': 39.242, 'eval_steps_per_second': 1.234, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhu\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\utils.py:790: UserWarning: There are 3 out of 2226 instances where the predictions for both options are equal. These instances are ignored in the accuracy computation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Final:\", trainer.evaluate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_FT_Kernel",
   "language": "python",
   "name": "llm_ft_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
