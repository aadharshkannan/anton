{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733d3c68-1e18-4278-8bb1-1ee2baf5b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install peft\n",
    "#%pip install --upgrade datasets tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263ebd5b-fc76-41e2-a733-dce8460fd563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:29:29.016568: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 21:29:29.030364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747344569.048330    8918 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747344569.053930    8918 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 21:29:29.071378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PromptTuningConfig,\n",
    "    PromptTuningInit,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a9c941-4f35-407d-93cc-f5f7590aba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/sagemaker-user/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Wed May 14 23:45:49 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/sagemaker-user/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Thu May 15 15:15:13 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2db92b-f31d-4057-9416-62d37e51d389",
   "metadata": {},
   "source": [
    "### Data loading & formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ee4255-7fbe-4160-a86c-58d2a48ebd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_binary(path: str, test_size: float = 0.1, seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    df = pd.read_csv(path, sep=';', usecols=['Premise', 'QCC', 'CorrectAnswer', 'Answer1', 'Answer2'])\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        text_base = f\"Premise: {row['Premise']} Question: {row['QCC']}\"\n",
    "        choices = [row['CorrectAnswer'], row['Answer1'], row['Answer2']]\n",
    "        for choice in choices:\n",
    "            label = 1 if choice == row['CorrectAnswer'] else 0\n",
    "            examples.append({\n",
    "                'text': f\"{text_base} Choice: {choice}\",\n",
    "                'label': label\n",
    "            })\n",
    "    ds = Dataset.from_pandas(pd.DataFrame(examples))\n",
    "    return ds.train_test_split(test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d174370-fd63-4fe1-bea8-88a35ce3b6fa",
   "metadata": {},
   "source": [
    "### Tokenizer & tokenization util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed750e3-d38e-4f75-98c5-2ab385337288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_and_collator(model_name: str = 'bert-base-uncased'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    collator = DataCollatorWithPadding(tokenizer)\n",
    "    return tokenizer, collator\n",
    "\n",
    "def tokenize_dataset(tokenizer):\n",
    "    def preprocess(batch):\n",
    "        tokenized = tokenizer(batch['text'], truncation=True, padding=False)\n",
    "        tokenized['label'] = batch['label']\n",
    "        return tokenized\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381b1fe-eb83-46df-9df1-0123738a8f9b",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9e6756-2c63-4c37-80ac-862bdd1dbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c371f-8221-4084-b299-7e38a5abc3b3",
   "metadata": {},
   "source": [
    "### Trainer builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819bfb5a-9174-4bb2-8ba7-0ae5f7f22d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lora_sequence_trainer(model_name, tokenizer, collator, train_ds, eval_ds,\n",
    "                               output_dir, epochs=20, train_batch=16, eval_batch=32,\n",
    "                               lora_r=4, lora_alpha=16, lora_dropout=0.1):\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    peft_config = LoraConfig(\n",
    "        task_type= TaskType.SEQ_CLS,\n",
    "        target_modules=['query', 'key'],\n",
    "        inference_mode=False,\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=train_batch,\n",
    "        per_device_eval_batch_size=eval_batch,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=2,\n",
    "        logging_steps=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy'\n",
    "    )\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd0d319-1fb8-40e0-be3a-a7c46f38d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_sequence_trainer(model_name, tokenizer, collator, train_ds, eval_ds,\n",
    "                                 output_dir, epochs=100, train_batch=16, eval_batch=32,\n",
    "                                 num_virtual_tokens=5):\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    peft_config = PromptTuningConfig(\n",
    "        task_type= TaskType.SEQ_CLS,\n",
    "        prompt_tuning_init=PromptTuningInit.RANDOM,\n",
    "        num_virtual_tokens=num_virtual_tokens,\n",
    "        tokenizer_name_or_path=tokenizer.name_or_path\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    print(model.print_trainable_parameters())\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=train_batch,\n",
    "        per_device_eval_batch_size=eval_batch,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=2,\n",
    "        logging_steps=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy'\n",
    "    )\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb597ff-55e0-4d72-b667-1f6fa5dfc7cc",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf10870-24bb-4d54-9325-999ccf2473bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(trainer, texts, max_length=512):\n",
    "    model = trainer.model\n",
    "    model.eval()\n",
    "\n",
    "    # Correct tokenizer\n",
    "    tokenizer = trainer.processing_class\n",
    "\n",
    "    # Tokenize\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Device‚Äêalign\n",
    "    device = next(model.parameters()).device\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    \n",
    "    import torch.nn.functional as F\n",
    "    probability = F.sigmoid(logits)\n",
    "    \n",
    "    # Predictions\n",
    "    return probability\n",
    "    #torch.argmax(logits, dim=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b45db-e8f0-4f7f-b07a-e01c1b59e37e",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9edb4b-dad5-4f42-a007-bffac1d72726",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/raw/CRASS_FTM_main_data_set.csv'\n",
    "OUTPUT_PATH_PROMPT = './causal-classifier-prompt'\n",
    "OUTPUT_PATH_LORA = './causal-classifier-lora'\n",
    "BASE_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32d0c8-2146-4f92-90d1-a23dc5b2c6aa",
   "metadata": {},
   "source": [
    "##### Load and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72520e3-a3ea-4900-8337-dc787f49f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_splits = load_and_prepare_binary(DATA_PATH)\n",
    "train_ds, test_ds = ds_splits['train'], ds_splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1073df9-3b81-41b5-a301-8e5229e2b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, collator = get_tokenizer_and_collator(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d0d0b4-ae27-464a-9537-bc0d246b48a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdc9211-5850-435d-bf63-a5f6b27e5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ds_splits[\"train\"][:6]\n",
    "features = tokenize_dataset(tokenizer)(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92fcff80-5faf-4bbc-8cbc-7c7206bb2092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] premise : a car speeds down a road. question : what would have happened if the car had slowed down on the road? choice : nothing would have happened. [SEP]',\n",
       " '[CLS] premise : a dog is in a house. question : what would have happened if the dog had not been in the house? choice : the dog would have been inside the house. [SEP]',\n",
       " '[CLS] premise : a man buys a hat. question : what would have happened if the man had sold the hat? choice : he would have lost money. [SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "[tokenizer.decode(features[\"input_ids\"][idx+ix]) for ix in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8bf81f-1467-4e81-85d1-42c1b610c22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674f90b9d91e44bbb1d10c0582b7b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb45b4e90fbd4861a68c1497a1795b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(tokenize_dataset(tokenizer), batched=True)\n",
    "test_ds = test_ds.map(tokenize_dataset(tokenizer), batched=True)\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2969aa-9d99-4cec-b79f-c9cd961d0aa7",
   "metadata": {},
   "source": [
    "#####  Baseline evaluation (no fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219e4f54-7dc4-405e-b825-79dc22200feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline evaluation (no training)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6301443576812744, 'eval_model_preparation_time': 0.0026, 'eval_accuracy': 0.6867469879518072, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.454, 'eval_samples_per_second': 182.805, 'eval_steps_per_second': 6.607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/05/15 21:30:02 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 06065e7405e041ee9745b882839f2b90: Failed to log run data: Exception: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='trainer_output/runs/May15_21-29-56_default' for run ID='06065e7405e041ee9745b882839f2b90'. Attempted logging new value './causal-classifier-prompt/runs/May15_21-30-02_default'.\n",
      "2025/05/15 21:30:03 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 06065e7405e041ee9745b882839f2b90: Failed to log run data: Exception: Changing param values is not allowed. Param with key='problem_type' was already logged with value='single_label_classification' for run ID='06065e7405e041ee9745b882839f2b90'. Attempted logging new value 'None'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline evaluation (no training)\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=2)\n",
    "base_trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=TrainingArguments(\n",
    "        per_device_eval_batch_size=32,\n",
    "        do_train=False\n",
    "    ),\n",
    "    eval_dataset=test_ds,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "print(base_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992fb4f-6e82-4757-8feb-183fcbe61cea",
   "metadata": {},
   "source": [
    "##### Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da65d1db-63fc-4844-8a3d-da69f70619ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tuning for sequence classification\n",
      "trainable params: 3,840 || all params: 109,487,618 || trainable%: 0.0035\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8918/290341359.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4700' max='4700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4700/4700 06:46, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>0.679449</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>0.678583</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.704100</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.677059</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.705600</td>\n",
       "      <td>0.676218</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.675479</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.674686</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.678800</td>\n",
       "      <td>0.673828</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.674700</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.672275</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.669600</td>\n",
       "      <td>0.671507</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.670717</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.670050</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.669273</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.686700</td>\n",
       "      <td>0.668536</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.687700</td>\n",
       "      <td>0.667876</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.667112</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.666411</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.665709</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.665021</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.664388</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.663669</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.662993</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.662350</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.661651</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.660972</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>0.660439</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.658600</td>\n",
       "      <td>0.659766</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.687400</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.664500</td>\n",
       "      <td>0.658531</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.657971</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>0.657364</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.656787</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.698900</td>\n",
       "      <td>0.656154</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.655613</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.655115</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.654622</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.654051</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.653578</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.653119</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.672800</td>\n",
       "      <td>0.652628</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.652058</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>0.651586</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.651096</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.650651</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.650226</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.649809</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.649422</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.649017</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.662700</td>\n",
       "      <td>0.648596</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.648236</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.670700</td>\n",
       "      <td>0.647841</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.666100</td>\n",
       "      <td>0.647427</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>0.647097</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.646785</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.652100</td>\n",
       "      <td>0.646451</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.664800</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.645850</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.645550</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>0.645286</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.644981</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.644713</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.644432</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.644187</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.643948</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.663900</td>\n",
       "      <td>0.643449</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.636600</td>\n",
       "      <td>0.643212</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.642999</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.659700</td>\n",
       "      <td>0.642790</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.664500</td>\n",
       "      <td>0.642589</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>0.642403</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.642223</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>0.642069</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.641885</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.641722</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.659400</td>\n",
       "      <td>0.641555</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.664500</td>\n",
       "      <td>0.641298</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>0.641184</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.641070</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.654800</td>\n",
       "      <td>0.640737</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.640623</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.658600</td>\n",
       "      <td>0.640532</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.642800</td>\n",
       "      <td>0.640446</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.640307</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.662800</td>\n",
       "      <td>0.640246</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.640189</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.651700</td>\n",
       "      <td>0.640051</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.640018</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.639989</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.639968</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>0.639953</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.662200</td>\n",
       "      <td>0.639945</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.639942</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6616513133049011, 'eval_accuracy': 0.6867469879518072, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.2148, 'eval_samples_per_second': 386.365, 'eval_steps_per_second': 13.965, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt tuning for sequence classification\")\n",
    "prompt_trainer = get_prompt_sequence_trainer(\n",
    "    BASE_MODEL, tokenizer, collator, train_ds, test_ds, OUTPUT_PATH_PROMPT\n",
    ")\n",
    "prompt_trainer.train()\n",
    "print(prompt_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86086d47-c752-4a54-8bb0-d76c511cb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_trainer.save_model(OUTPUT_PATH_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c59d3c-3a63-46e1-803c-ec46c4c5a51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA tuning for sequence classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7500/2840488858.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 01:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.719300</td>\n",
       "      <td>0.601047</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.626700</td>\n",
       "      <td>0.593062</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.576818</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.556212</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.543652</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.539728</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.535577</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.572800</td>\n",
       "      <td>0.534732</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.582700</td>\n",
       "      <td>0.536209</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.529400</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.672300</td>\n",
       "      <td>0.531275</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>0.528386</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.528176</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.527726</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.700500</td>\n",
       "      <td>0.525544</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.525483</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.527171</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.527525</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.520500</td>\n",
       "      <td>0.526969</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6010472178459167, 'eval_accuracy': 0.6987951807228916, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.1812, 'eval_samples_per_second': 457.978, 'eval_steps_per_second': 16.553, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"LoRA tuning for sequence classification\")\n",
    "lora_trainer = get_lora_sequence_trainer(\n",
    "    BASE_MODEL, tokenizer, collator, train_ds, test_ds, OUTPUT_PATH_LORA\n",
    ")\n",
    "lora_trainer.train()\n",
    "print(lora_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b27e114-a064-4121-8e57-f944661c5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_trainer.save_model(OUTPUT_PATH_LORA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "075a6f05-0e13-44ea-9e35-8ed9bb163b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5016, 0.3526],\n",
       "        [0.5235, 0.3329],\n",
       "        [0.5301, 0.3208]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"premise: A girl kisses a boy. question: What would have happened if the girl had killed the boy? choice: She would have been liable to prosecution.\",\n",
    "\"premise:  A girl kisses a boy. question: What would have happened if the girl had killed the boy? The boy would have been arrested for assault\",\n",
    "\"premise: A girl kisses a boy. question: What would have happened if the girl had killed the boy? choice: The boy would have kissed the girl\"]\n",
    "\n",
    "predict_sequence(lora_trainer,texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a1dcd3-cc0a-472f-8423-9005ce1731b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, module in base_model.named_modules():\n",
    "#    print(name)\n",
    "#    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5afc5574-f770-46dd-b433-bfb1a71328c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_prompt_sequence(\n",
    "    prompt_tuned_dir: str,\n",
    "    base_model_name: str,\n",
    "    tokenizer,\n",
    "    texts: list[str],\n",
    "    max_length: int = 492,# 512 earlier max length minus 20 virtual tokens\n",
    "    num_virtual_tokens: int = 20,    # MUST match what you used during training\n",
    "    device: torch.device | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a prompt-tuned model and run inference.  We first bump up\n",
    "    the position embeddings by num_virtual_tokens so that\n",
    "    512 + num_virtual_tokens positions are supported.\n",
    "    \"\"\"\n",
    "    # 1) Load the frozen base model\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        base_model_name,\n",
    "        num_labels=2,\n",
    "    )\n",
    "    \n",
    "    # 3) Inject the prompt-tuned weights\n",
    "    model = PeftModel.from_pretrained(base_model, prompt_tuned_dir)\n",
    "    model.eval()\n",
    "\n",
    "    # 4) Move to device\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 5) Tokenize normally (no need to add ‚Äú[VIRT_0]...[VIRT_19]‚Äù yourself)\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    # 6) Forward pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "\n",
    "    # 7) Convert to probabilities\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 1) Find the ModuleDict that contains the prompt encoder ‚Äî‚Äî‚Äî\n",
    "    prompt_enc_dict = None\n",
    "    for name, module in model.named_modules():\n",
    "        if name.endswith(\"prompt_encoder\"):\n",
    "            prompt_enc_dict = module\n",
    "            break\n",
    "    assert prompt_enc_dict is not None, \"Prompt-encoder not found!\"\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 2) Extract the actual PromptEmbedding inside the dict ‚Äî‚Äî‚Äî\n",
    "    # It usually has a single key (\"default\"), but this is robust:\n",
    "    prompt_encoder = None\n",
    "    for sub in prompt_enc_dict.children():\n",
    "        # first child should be PromptEmbedding\n",
    "        prompt_encoder = sub\n",
    "        break\n",
    "    assert prompt_encoder is not None, \"No PromptEmbedding inside ModuleDict!\"\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 3) Pull out the soft-prompt embeddings ‚Äî‚Äî‚Äî\n",
    "    # PromptEmbedding has an `.embedding` module\n",
    "    soft_embs: torch.Tensor = prompt_encoder.embedding.weight\n",
    "    # shape = (num_virtual_tokens, hidden_size)\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 4) Get the base model‚Äôs real token embeddings ‚Äî‚Äî‚Äî\n",
    "    base_embs: torch.Tensor = model.base_model.get_input_embeddings().weight\n",
    "    # shape = (vocab_size, hidden_size)\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 5) Compute cosine similarities & top-k neighbors ‚Äî‚Äî‚Äî\n",
    "    V, H = soft_embs.shape\n",
    "    T, _ = base_embs.shape\n",
    "    soft_norm = F.normalize(soft_embs, dim=1)  # (V, H)\n",
    "    base_norm = F.normalize(base_embs, dim=1)  # (T, H)\n",
    "    \n",
    "    sims = torch.matmul(soft_norm, base_norm.t())  # (V, T)\n",
    "    top_k = 5\n",
    "    values, indices = sims.topk(top_k, dim=1)      # (V, K)\n",
    "    \n",
    "    # ‚Äî‚Äî‚Äî 6) Decode & print ‚Äî‚Äî‚Äî\n",
    "    for i in range(V):\n",
    "        toks = tokenizer.convert_ids_to_tokens(indices[i].tolist())\n",
    "        scores = [f\"{v:.3f}\" for v in values[i].tolist()]\n",
    "        print(f\"Virtual token #{i:2d} ‚Üí\", \", \".join(f\"{tok}({sc})\" for tok, sc in zip(toks, scores)))\n",
    "            \n",
    "    return probs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a82b0d4-63a7-465b-80a1-6afa6d26a1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual token # 0 ‚Üí ##urbed(0.099), british(0.098), marquez(0.095), united(0.092), fang(0.092)\n",
      "Virtual token # 1 ‚Üí republic(0.123), ##ality(0.115), ##ur(0.114), duo(0.113), florida(0.107)\n",
      "Virtual token # 2 ‚Üí adam(0.092), cancel(0.088), factors(0.088), walter(0.086), ##gg(0.084)\n",
      "Virtual token # 3 ‚Üí premier(0.143), morgan(0.132), cup(0.129), trophy(0.129), tamil(0.123)\n",
      "Virtual token # 4 ‚Üí trees(0.123), selections(0.119), ##oted(0.114), sonya(0.113), buttons(0.111)\n",
      "Prompt-Tuned Probabilities:\n",
      " tensor([[0.5348, 0.4652],\n",
      "        [0.4974, 0.5026],\n",
      "        [0.5341, 0.4659]])\n"
     ]
    }
   ],
   "source": [
    "prompt_probs = predict_prompt_sequence(\n",
    "    prompt_tuned_dir=OUTPUT_PATH_PROMPT,\n",
    "    base_model_name=BASE_MODEL,\n",
    "    tokenizer=tokenizer,\n",
    "    texts=texts,\n",
    ")\n",
    "print(\"Prompt-Tuned Probabilities:\\n\", prompt_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
