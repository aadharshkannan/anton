from __future__ import annotations
"""generate_responses.py

Constructs fine‑tuning snippets from parsed WhatsApp sessions.

Each snippet has the shape::

    {
        "context": "<prior messages formatted>",
        "output": "<target author's next message>"
    }

The script expects:
  1. A *processed* sessions JSON file inside ``data/processed`` generated by
     ``parse_whatsapp.py``.
  2. The *author* (speaker) for whom we are creating training examples.

The resulting dataset is written as **JSONL** to the same folder with a
``_train`` suffix (e.g. ``personal_chat_sessions_train.jsonl``).

Usage (from repository root)::

    python scripts/generate_responses.py personal_chat_sessions.json "Sparsha"
"""

import argparse
import json
from pathlib import Path
from typing import List, Iterable

from shared_models import Exchange, Session, TrainingSnippet
from pydantic import ValidationError

# ---------------------------------------------------------------------------
# Core helpers
# ---------------------------------------------------------------------------

def load_sessions(path: Path) -> List[Session]:
    """Load the processed sessions JSON into validated ``Session`` objects."""
    try:
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError as e:
        raise SystemExit(f"❌ Input file not found: {path}") from e
    except json.JSONDecodeError as e:
        raise SystemExit(f"❌ Invalid JSON in {path}: {e}") from e

    try:
        return [Session(**sess) for sess in data]
    except ValidationError as e:
        raise SystemExit(f"❌ Validation error while loading sessions: {e}") from e


def iter_training_snippets(sessions: Iterable[Session], target_author: str) -> Iterable[TrainingSnippet]:
    """Yield TrainingSnippet objects for every message by *target_author* that has at least one prior exchange in the session."""
    for sess in sessions:
        context_lines: List[str] = []
        for idx, exch in enumerate(sess.exchanges):
            formatted = f"{exch.author}: {exch.message}"

            if exch.author == target_author:
                # Only create a snippet if there is prior context (i.e., idx > 0)
                if context_lines:
                    yield TrainingSnippet(
                        context="\n".join(context_lines),
                        output=exch.message,
                    )
            # Update context after evaluating (so that the current author line is included for next snippets)
            context_lines.append(formatted)


def save_snippets(snippets: Iterable[TrainingSnippet], output_path: Path) -> None:
    """Write snippets to *output_path* in JSON Lines format."""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as fp:
        count = 0
        for snip in snippets:
            fp.write(snip.model_dump_json() + "\n")
            count += 1
    print(f"✅ Wrote {count} training snippets to {output_path}")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def parse_args():
    parser = argparse.ArgumentParser(description="Generate fine‑tuning snippets from WhatsApp sessions.")
    parser.add_argument(
        "input_filename",
        help="Processed sessions JSON filename inside data/processed (e.g. personal_chat_sessions.json)",
    )
    parser.add_argument(
        "author",
        help="Target author (speaker) for whom to build training data, e.g. 'Sparsha'",
    )
    return parser.parse_args()


def main():
    args = parse_args()

    processed_dir = Path("data/processed")
    input_path = processed_dir / args.input_filename

    sessions = load_sessions(input_path)

    snippets = list(iter_training_snippets(sessions, args.author))

    if not snippets:
        raise SystemExit(f"⚠️ No snippets generated. Check that author '{args.author}' exists in the chat data.")

    output_path = processed_dir / (input_path.stem + "_train.jsonl")
    save_snippets(snippets, output_path)


if __name__ == "__main__":
    main()
