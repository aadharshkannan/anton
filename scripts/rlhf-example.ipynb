{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45aed788",
   "metadata": {},
   "source": [
    "### RLHF to check ACD works\n",
    "This notebook uses ACD (Adversarial Contrastive Distillation) a HELLASWAG inspired data generation to fit RLHF. It also uses a portion of the dataset to measure model performance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b6c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Hugging Face Transformers & Datasets\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    #AutoModelForSeq2SeqLM,    \n",
    "    AutoModelForSequenceClassification,\n",
    "    GenerationConfig,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# PEFT & TRL for RLHF\n",
    "from peft import PeftModel, LoraConfig, TaskType, get_peft_model\n",
    "from trl import (\n",
    "    PPOTrainer,\n",
    "    PPOConfig, \n",
    "    AutoModelForCausalLMWithValueHead,\n",
    "    #AutoModelForSeq2SeqLMWithValueHead,\n",
    "    create_reference_model\n",
    ")\n",
    "\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "# Evaluation\n",
    "import evaluate\n",
    "\n",
    "# Utilities\n",
    "from shared_models import HellaSwagEntry\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead79baf",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3400b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/hellaswag_format/personal_chat_sessions_train_hellaswag.jsonl\")\n",
    "REWARD_MODEL_PATH = \"../data/models/reward_model_ckpts/checkpoint-3762\"\n",
    "#REWARD_MODEL_PATH = \"trl-internal-testing/tiny-Qwen2ForSequenceClassification-2.5\"\n",
    "RLHF_CKPTS_DIR = \"../data/models/rlhf_ckpts\"\n",
    "BASE_MODEL_NAME = \"trl-internal-testing/tiny-Qwen2ForCausalLM-2.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172118e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22,282 examples\n"
     ]
    }
   ],
   "source": [
    "# Function to read JSONL via Pydantic\n",
    "def load_jsonl_pydantic(path: Path):\n",
    "    \"\"\"Yield HellaSwagEntry objects parsed with Pydantic.\"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield HellaSwagEntry.model_validate_json(line)\n",
    "\n",
    "# Load records\n",
    "records = list(load_jsonl_pydantic(DATA_PATH))\n",
    "print(f\"Loaded {len(records):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb7288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22,282 examples from ..\\data\\hellaswag_format\\personal_chat_sessions_train_hellaswag.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b3d37dd37548dabf5d975718234d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a4c922da694e78970d46c8d0a369b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_jsonl_pydantic(path: Path):\n",
    "    \"\"\"Yield HellaSwagEntry objects parsed with Pydantic.\"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield HellaSwagEntry.model_validate_json(line)\n",
    "\n",
    "records = list(load_jsonl_pydantic(DATA_PATH))\n",
    "print(f\"Loaded {len(records):,} examples from {DATA_PATH}\")\n",
    "\n",
    "# Build context-response pairs\n",
    "data_pairs = []\n",
    "for ex in load_jsonl_pydantic(DATA_PATH):\n",
    "    endings    = [ex.ending0, ex.ending1, ex.ending2, ex.ending3, ex.ending4]\n",
    "    human_resp = endings[ex.label].strip()\n",
    "    data_pairs.append({\n",
    "        \"context\": ex.context.strip(),\n",
    "        \"human_resp\": human_resp\n",
    "    })\n",
    "\n",
    "raw_dataset = Dataset.from_list(data_pairs)\n",
    "train_test  = raw_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds    = train_test[\"train\"]\n",
    "test_ds     = train_test[\"test\"]\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "# Tokenization function\n",
    "max_len = 128\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"context\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_len,\n",
    "    )\n",
    "\n",
    "# Map tokenization over the datasets\n",
    "train_ds = train_ds.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=train_ds.column_names\n",
    ")\n",
    "test_ds = test_ds.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names\n",
    ")\n",
    "\n",
    "# Use a data collator to batch and pad\n",
    "data_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565d341",
   "metadata": {},
   "source": [
    "#### Load and Prepare Base LLM + LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946ea7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    print(f\"\\ntrainable model parameters: {trainable_model_params}\\\n",
    "    \\nall model parameters: {all_model_params}\\\n",
    "    \\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d607ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151665, 8)\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "          (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "          (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "          (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "          (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "          (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=8, out_features=151665, bias=False)\n",
      ")\n",
      "model\n",
      "Qwen2Model(\n",
      "  (embed_tokens): Embedding(151665, 8)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x Qwen2DecoderLayer(\n",
      "      (self_attn): Qwen2Attention(\n",
      "        (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "      )\n",
      "      (mlp): Qwen2MLP(\n",
      "        (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "        (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "        (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "      (post_attention_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "  (rotary_emb): Qwen2RotaryEmbedding()\n",
      ")\n",
      "model.embed_tokens\n",
      "Embedding(151665, 8)\n",
      "model.layers\n",
      "ModuleList(\n",
      "  (0-1): 2 x Qwen2DecoderLayer(\n",
      "    (self_attn): Qwen2Attention(\n",
      "      (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "      (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "    )\n",
      "    (mlp): Qwen2MLP(\n",
      "      (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "      (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "      (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "      (act_fn): SiLU()\n",
      "    )\n",
      "    (input_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "    (post_attention_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "  )\n",
      ")\n",
      "model.layers.0\n",
      "Qwen2DecoderLayer(\n",
      "  (self_attn): Qwen2Attention(\n",
      "    (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "  )\n",
      "  (mlp): Qwen2MLP(\n",
      "    (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "    (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "    (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "  (post_attention_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      ")\n",
      "model.layers.0.self_attn\n",
      "Qwen2Attention(\n",
      "  (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      ")\n",
      "model.layers.0.self_attn.q_proj\n",
      "Linear(in_features=8, out_features=8, bias=True)\n",
      "model.layers.0.self_attn.k_proj\n",
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "model.layers.0.self_attn.v_proj\n",
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "model.layers.0.self_attn.o_proj\n",
      "Linear(in_features=8, out_features=8, bias=False)\n",
      "model.layers.0.mlp\n",
      "Qwen2MLP(\n",
      "  (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "  (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "  (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.0.mlp.gate_proj\n",
      "Linear(in_features=8, out_features=32, bias=False)\n",
      "model.layers.0.mlp.up_proj\n",
      "Linear(in_features=8, out_features=32, bias=False)\n",
      "model.layers.0.mlp.down_proj\n",
      "Linear(in_features=32, out_features=8, bias=False)\n",
      "model.layers.0.mlp.act_fn\n",
      "SiLU()\n",
      "model.layers.0.input_layernorm\n",
      "Qwen2RMSNorm((8,), eps=1e-06)\n",
      "model.layers.0.post_attention_layernorm\n",
      "Qwen2RMSNorm((8,), eps=1e-06)\n",
      "model.layers.1\n",
      "Qwen2DecoderLayer(\n",
      "  (self_attn): Qwen2Attention(\n",
      "    (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      "  )\n",
      "  (mlp): Qwen2MLP(\n",
      "    (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "    (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "    (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      "  (post_attention_layernorm): Qwen2RMSNorm((8,), eps=1e-06)\n",
      ")\n",
      "model.layers.1.self_attn\n",
      "Qwen2Attention(\n",
      "  (q_proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (k_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (v_proj): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
      ")\n",
      "model.layers.1.self_attn.q_proj\n",
      "Linear(in_features=8, out_features=8, bias=True)\n",
      "model.layers.1.self_attn.k_proj\n",
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "model.layers.1.self_attn.v_proj\n",
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "model.layers.1.self_attn.o_proj\n",
      "Linear(in_features=8, out_features=8, bias=False)\n",
      "model.layers.1.mlp\n",
      "Qwen2MLP(\n",
      "  (gate_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "  (up_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "  (down_proj): Linear(in_features=32, out_features=8, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.1.mlp.gate_proj\n",
      "Linear(in_features=8, out_features=32, bias=False)\n",
      "model.layers.1.mlp.up_proj\n",
      "Linear(in_features=8, out_features=32, bias=False)\n",
      "model.layers.1.mlp.down_proj\n",
      "Linear(in_features=32, out_features=8, bias=False)\n",
      "model.layers.1.mlp.act_fn\n",
      "SiLU()\n",
      "model.layers.1.input_layernorm\n",
      "Qwen2RMSNorm((8,), eps=1e-06)\n",
      "model.layers.1.post_attention_layernorm\n",
      "Qwen2RMSNorm((8,), eps=1e-06)\n",
      "model.norm\n",
      "Qwen2RMSNorm((8,), eps=1e-06)\n",
      "model.rotary_emb\n",
      "Qwen2RotaryEmbedding()\n",
      "lm_head\n",
      "Linear(in_features=8, out_features=151665, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'> model is loaded from 'trl-internal-testing/tiny-Qwen2ForCausalLM-2.5', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\",\"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "# Load base model and attach PEFT adapter\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    is_decoder=True\n",
    ")\n",
    "\n",
    "for name, module in base_model.named_modules():\n",
    "    print(name)\n",
    "    print(module)\n",
    "\n",
    "dppo_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    is_trainable=True,\n",
    ")\n",
    "# Create reference model (frozen copy)\n",
    "ref_model = create_reference_model(dppo_model)\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(BASE_MODEL_NAME)\n",
    "gen_config.min_length = 1\n",
    "gen_config.max_new_tokens = 50\n",
    "\n",
    "dppo_model.generation_config = gen_config\n",
    "ref_model.generation_config = gen_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571cdd49",
   "metadata": {},
   "source": [
    "#### Prepare Human-Preference Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38737627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model labels: {0: 'LABEL_0'}\n"
     ]
    }
   ],
   "source": [
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_PATH, device_map=\"auto\")\n",
    "if reward_tokenizer.pad_token is None:\n",
    "    reward_tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    REWARD_MODEL_PATH,\n",
    "    num_labels=1\n",
    ")\n",
    "\n",
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    REWARD_MODEL_PATH,\n",
    "    num_labels=1\n",
    ")\n",
    "\n",
    "print(\"Reward model labels:\", reward_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the original generate method\n",
    "orig_generate = dppo_model.generate\n",
    "\n",
    "# 2. Define a wrapper that injects our kwarg\n",
    "def generate_with_dict(*args, **kwargs):\n",
    "    # Ensure we get a ModelOutput with .logits\n",
    "    kwargs.setdefault(\"return_dict_in_generate\", True)\n",
    "    return orig_generate(*args, **kwargs)\n",
    "\n",
    "# 3. Apply the patch to both models\n",
    "dppo_model.generate = generate_with_dict\n",
    "ref_model.generate  = generate_with_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cebbbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Inference pipeline (raw logits)\n",
    "preference_pipe = pipeline(\n",
    "    'text-classification',\n",
    "    model=reward_model,\n",
    "    tokenizer=reward_tokenizer,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "reward_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\", \"batch_size\": 16}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40d629",
   "metadata": {},
   "source": [
    "#### Set up PPO-Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a74d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    output_dir   = RLHF_CKPTS_DIR,\n",
    "    num_ppo_epochs = 3,\n",
    "    mini_batch_size = 4,\n",
    "    batch_size      = 16\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model        = dppo_model,\n",
    "    ref_model    = ref_model,\n",
    "    processing_class    = tokenizer,\n",
    "    reward_model = reward_model,\n",
    "    value_model=value_model,\n",
    "    peft_config      = lora_config,  \n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset  = test_ds,\n",
    "    data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e36713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===training policy===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start RLHF training loop\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mppo_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\source\\Anton\\anton\\.venv\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:447\u001b[39m, in \u001b[36mPPOTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    446\u001b[39m     ref_output = forward(ref_policy, query_response, processing_class.pad_token_id)\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m ref_logits = \u001b[43mref_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogits\u001b[49m[:, context_length - \u001b[32m1\u001b[39m : -\u001b[32m1\u001b[39m]\n\u001b[32m    448\u001b[39m ref_logits /= args.temperature + \u001b[32m1e-7\u001b[39m\n\u001b[32m    449\u001b[39m ref_logprob = selective_log_softmax(ref_logits, response)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "# Start RLHF training loop\n",
    "ppo_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_FT_Kernel",
   "language": "python",
   "name": "llm_ft_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
