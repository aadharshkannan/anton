{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a88f75a-3a58-4aba-9882-314b4e6af00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install peft\n",
    "#%pip install trl\n",
    "#%pip install dataset -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d469b3e-4008-4141-9372-750e7860da35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 15:26:10.102998: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 15:26:10.116290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746804370.133763    1737 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746804370.139150    1737 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 15:26:10.156017: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import CPOConfig, CPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ffd89c-c9eb-4348-a23f-0cbc84fc1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH            = Path(\"./personal_chat_sessions_train_hellaswag.jsonl\")\n",
    "MIN_WORDS            = 3\n",
    "BASE_MODEL_NAME      = \"Qwen/Qwen2.5-0.5B\"\n",
    "REWARD_MODEL_PATH    = \"./reward_model_ckpts_fix/checkpoint-7506\"\n",
    "OUTPUT_MODEL_PATH    = \"./rlhf_cpo_ckpts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fcb151-daa1-43e3-8338-df42af081f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_pydantic(path: Path):\n",
    "    from shared_models import HellaSwagEntry\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield HellaSwagEntry.model_validate_json(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83382f2-170f-4782-9c33-9e4fd0bd3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pairs = []\n",
    "for ex in load_jsonl_pydantic(DATA_PATH):\n",
    "    endings = [ex.ending0, ex.ending1, ex.ending2, ex.ending3, ex.ending4]\n",
    "    human_resp = endings[ex.label].strip()\n",
    "    if len(ex.context.split()) >= MIN_WORDS:\n",
    "        data_pairs.append({\"context\": ex.context.strip(), \"human_resp\": human_resp})\n",
    "raw_dataset = Dataset.from_list(data_pairs)\n",
    "train_test = raw_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_raw, test_raw = train_test[\"train\"], train_test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00aeda9e-d333-40dc-8358-cb5dc8c51318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pref_pairs(dataset: Dataset, seed: int = 42) -> Dataset:\n",
    "    random.seed(seed)\n",
    "    samples = []\n",
    "    all_resps = [d['human_resp'] for d in dataset]\n",
    "    for d in dataset:\n",
    "        neg = random.choice(all_resps)\n",
    "        while neg == d['human_resp']:\n",
    "            neg = random.choice(all_resps)\n",
    "        samples.append({\n",
    "            'prompt': d['context'].rstrip(),\n",
    "            'chosen': '\\n' + d['human_resp'].lstrip(),\n",
    "            'rejected': '\\n' + neg.lstrip()\n",
    "        })\n",
    "    return Dataset.from_list(samples)\n",
    "\n",
    "train_cpo_ds = create_pref_pairs(train_raw)\n",
    "test_cpo_ds  = create_pref_pairs(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6445e3-c74f-41e3-b7d7-f63650a97747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForSequenceClassification(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=896, out_features=4, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=4, out_features=896, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=896, out_features=4, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=4, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (score): ModulesToSaveWrapper(\n",
       "    (original_module): Linear(in_features=896, out_features=1, bias=False)\n",
       "    (modules_to_save): ModuleDict(\n",
       "      (default): Linear(in_features=896, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_PATH, padding_side=\"left\")\n",
    "\n",
    "if reward_tokenizer.pad_token is None:\n",
    "    reward_tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "reward_tokenizer.max_length = 128\n",
    "reward_tokenizer.chat_template = getattr(reward_tokenizer, \"chat_template\", None)    \n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    REWARD_MODEL_PATH,\n",
    "    num_labels=1\n",
    ")\n",
    "reward_model.config.pad_token_id = reward_tokenizer.pad_token_id\n",
    "\n",
    "reward_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4dc691f-52d8-49a2-b319-a9ea290a5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(batch):\n",
    "    # Tokenize chosen and rejected separately\n",
    "    chosen_inputs = reward_tokenizer(\n",
    "        batch[\"chosen\"],\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    rejected_inputs = reward_tokenizer(\n",
    "        batch[\"rejected\"],\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # raw logits\n",
    "        score_chosen = reward_model(**chosen_inputs).logits.squeeze(-1)\n",
    "        score_rejected = reward_model(**rejected_inputs).logits.squeeze(-1)\n",
    "    \n",
    "    # convert to python floats or lists\n",
    "    return {\n",
    "        \"score_chosen\": score_chosen.cpu().tolist(),\n",
    "        \"score_rejected\": score_rejected.cpu().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e41267d-eb65-4930-b822-c51767d62c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_problematic_examples(dataset, tokenizer):\n",
    "    \"\"\"\n",
    "    Remove examples where truncation causes chosen vs. rejected\n",
    "    token lengths to differ by >1 token.\n",
    "    \"\"\"\n",
    "    def is_valid(example):\n",
    "        # tokenize with truncation to the same max_length the trainer will use\n",
    "        enc_chosen  = tokenizer(example[\"chosen\"],  truncation=True, max_length=tokenizer.model_max_length)\n",
    "        enc_reject  = tokenizer(example[\"rejected\"], truncation=True, max_length=tokenizer.model_max_length)\n",
    "        return abs(len(enc_chosen.input_ids) - len(enc_reject.input_ids)) <= 1\n",
    "\n",
    "    return dataset.filter(is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd891ae-41c6-453f-8c05-706e075d3533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad1ae7faf0444958bb1571573686af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da539a317ac940cbaca7276a280630fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map to add score_chosen and score_rejected columns\n",
    "train_cpo_ds_bulk = train_cpo_ds.map(compute_scores, batched=True, batch_size=8)\n",
    "test_cpo_ds_bulk  = test_cpo_ds.map(compute_scores, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9862ea-5731-4bab-96b7-d1f6a80308ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_tok = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, padding_side=\"left\")\n",
    "if policy_tok.pad_token is None:\n",
    "    policy_tok.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "policy_tok.max_length = 128\n",
    "policy_tok.chat_template = getattr(policy_tok, \"chat_template\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceaa4fb8-a3ef-4554-8d66-9f0cc9d3729f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c7db075fe74019a51564dd7081df56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/19955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fff262c0454e39b54be6df42143f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cpo_ds = filter_problematic_examples(train_cpo_ds_bulk, policy_tok)\n",
    "test_cpo_ds  = filter_problematic_examples(test_cpo_ds_bulk,  policy_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63ab6db-7c4d-4d01-aed3-107fb6a070b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "      <th>score_chosen</th>\n",
       "      <th>score_rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparsha: How are you feeling\\nSparsha: I love ...</td>\n",
       "      <td>\\nI love u</td>\n",
       "      <td>\\nBrain fried</td>\n",
       "      <td>-3.356873</td>\n",
       "      <td>-2.452819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsha: null\\nAadharsh Kannan: Love you\\nSpar...</td>\n",
       "      <td>\\nI miss u already</td>\n",
       "      <td>\\nAnd trying to finish assignment</td>\n",
       "      <td>-3.161788</td>\n",
       "      <td>-1.905694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aadharsh Kannan: I love ❤️ you\\nSparsha: null\\...</td>\n",
       "      <td>\\nYour shrink is here</td>\n",
       "      <td>\\nSpoke to them</td>\n",
       "      <td>-4.044352</td>\n",
       "      <td>-0.517105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt                 chosen  \\\n",
       "0  Sparsha: How are you feeling\\nSparsha: I love ...             \\nI love u   \n",
       "1  Sparsha: null\\nAadharsh Kannan: Love you\\nSpar...     \\nI miss u already   \n",
       "2  Aadharsh Kannan: I love ❤️ you\\nSparsha: null\\...  \\nYour shrink is here   \n",
       "\n",
       "                            rejected  score_chosen  score_rejected  \n",
       "0                      \\nBrain fried     -3.356873       -2.452819  \n",
       "1  \\nAnd trying to finish assignment     -3.161788       -1.905694  \n",
       "2                    \\nSpoke to them     -4.044352       -0.517105  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cpo_ds.take(3).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c55f524-f9a0-458f-9c90-542b7507657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPOTrainerWithLoRA:\n",
    "    \"\"\"\n",
    "    Trainer that wraps TRL's CPOTrainer with LoRA (PEFT) configuration.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        train_dataset: Dataset,\n",
    "        eval_dataset: Dataset,\n",
    "        output_dir: str,\n",
    "        lora_r: int = 4,\n",
    "        lora_alpha: int = 32,\n",
    "        lora_dropout: float = 0.05,\n",
    "        target_modules=None,\n",
    "        per_device_train_batch_size: int = 1,\n",
    "        per_device_eval_batch_size: int = 4,\n",
    "        num_train_epochs: int = 3,\n",
    "        seed: int = 42,\n",
    "        report_to: str = \"none\"\n",
    "    ):\n",
    "        self.model_name     = model_name\n",
    "        self.train_dataset  = train_dataset\n",
    "        self.eval_dataset   = eval_dataset\n",
    "        self.output_dir     = output_dir\n",
    "        self.seed           = seed\n",
    "\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "        self.tokenizer.max_length = 128\n",
    "        self.tokenizer.chat_template = getattr(self.tokenizer, \"chat_template\", None)\n",
    "\n",
    "        # Load policy model\n",
    "        self.policy = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "        self.policy.config.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "        # Configure LoRA via PEFT\n",
    "        self.peft_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            lora_dropout=lora_dropout,\n",
    "            target_modules=target_modules or [\"q_proj\"],\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        self.policy = get_peft_model(self.policy, self.peft_config)\n",
    "\n",
    "        # Set up CPOConfig\n",
    "        self.cpo_config = CPOConfig(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            remove_unused_columns=False,\n",
    "            seed=seed,\n",
    "            report_to=report_to\n",
    "        )\n",
    "\n",
    "        # Initialize TRL CPO trainer\n",
    "        self.trainer = CPOTrainer(\n",
    "            model=self.policy,\n",
    "            args=self.cpo_config,\n",
    "            processing_class=self.tokenizer,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.eval_dataset,\n",
    "            peft_config=self.peft_config\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Run the CPO training loop.\"\"\"\n",
    "        self.trainer.train()\n",
    "\n",
    "    def save(self, save_directory: str = None):\n",
    "        \"\"\"Save the fine-tuned policy model and tokenizer.\"\"\"\n",
    "        target_dir = save_directory or self.output_dir\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        self.policy.save_pretrained(target_dir)\n",
    "        self.tokenizer.save_pretrained(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2f74521-7127-40e7-bf67-0b4d621edbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2bdac48-a969-4bbe-8677-143e5291135d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd52425d51a545a882dbded2858d69ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62e26bad00e435db3144e607917665b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93392c7491c4e9ba1899a9da262cdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539a17ab779244f8b2558f1164baf8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5078ab9189c448e2a458d803c9080b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8933d0d5464c44a58b61f6f13bb5b244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and run\n",
    "trainer = CPOTrainerWithLoRA(\n",
    "    model_name=BASE_MODEL_NAME,\n",
    "    train_dataset=train_cpo_ds,\n",
    "    eval_dataset=test_cpo_ds,\n",
    "    output_dir=OUTPUT_MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b1e15a-c52b-445b-8b6f-1d69c1a8cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33761285-67c3-49b7-bdd1-c53c6605a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17658' max='17658' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17658/17658 2:14:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>6.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.648600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>4.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>4.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>4.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>4.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>4.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>4.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>4.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>4.695600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>4.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>4.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>4.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>4.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>4.705300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>4.634000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33546a85-e69c-41cc-88b4-9569c6c0d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57330b4-ac4f-4a8f-a31b-88a1a51ce785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
